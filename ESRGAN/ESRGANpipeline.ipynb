{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCICBTwpaMRR"
   },
   "source": [
    "# ESRGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzHvc7pvas39"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zP-UcBG51XP_"
   },
   "source": [
    "## Create LR images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7YHfl6V1V1a"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import cv2\n",
    "\n",
    "scale = 1/4\n",
    "\n",
    "inputdir = './data/DIV2K/ESRGAN/valid'\n",
    "outputdir = './data/DIV2K/ESRGAN/validLR'\n",
    "try:\n",
    "  os.makedirs(outputdir)\n",
    "except:\n",
    "  print('lr dir exists')\n",
    "# Get all image paths\n",
    "image_file_names = os.listdir(inputdir)\n",
    "\n",
    "for image_file_name in image_file_names:\n",
    "  image = cv2.imread(f\"{inputdir}/{image_file_name}\", cv2.IMREAD_UNCHANGED)\n",
    "  img_resized = cv2.resize(image, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "  cv2.imwrite(f\"{outputdir}/{image_file_name.split('.')[-2]}.{image_file_name.split('.')[-1]}\", img_resized)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6Q363fdmS7E"
   },
   "source": [
    "## Divide into train valid test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foRwE0jEmWO9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "percent_train = 0.8\n",
    "percent_valid = 0.6\n",
    "\n",
    "path = \"./data/Bubbles\"\n",
    "path_full = path+\"/bubblesHR\"\n",
    "\n",
    "os.makedirs(path+\"/train\")\n",
    "os.makedirs(path+\"/valid\")\n",
    "os.makedirs(path+\"/test\")\n",
    "\n",
    "image_size = 480\n",
    "'''\n",
    "full_dataset = TrainValidImageDataset(path_full,\n",
    "                                            image_size,\n",
    "                                            esrgan_config.upscale_factor,\n",
    "                                            \"Valid\")\n",
    "\n",
    "\n",
    "train_size = int(percent_train * len(full_dataset))\n",
    "valid_size = int((len(full_dataset) - train_size)*percent_valid)\n",
    "test_size = int((len(full_dataset) - train_size)*(1-percent_valid))\n",
    "if train_size+valid_size+test_size < len(full_dataset):\n",
    "  train_size+=1\n",
    "elif train_size+valid_size+test_size > len(full_dataset):\n",
    "  train_size-=1\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, valid_size, test_size])\n",
    "\n",
    "torch.save(data[0], '/content/train_loader/img/train_transformed_img{}'.format(i))\n",
    "'''\n",
    "\n",
    "# Get all image paths\n",
    "image_file_names = os.listdir(path_full)\n",
    "\n",
    "for image_file_name in image_file_names:\n",
    "  image = cv2.imread(f\"{path_full}/{image_file_name}\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "  save_dir = \"\"\n",
    "  if percent_train > random.random(): #train\n",
    "    save_dir = path+\"/train\"\n",
    "  elif percent_valid > random.random(): # valid\n",
    "    save_dir = path+\"/valid\"\n",
    "  else:\n",
    "    save_dir = path+\"/test\"\n",
    "  \n",
    "  # Save image\n",
    "  \n",
    "  cv2.imwrite(f\"{save_dir}/{image_file_name}\", image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_azGlN4daQAt"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 101153,
     "status": "ok",
     "timestamp": 1678798793199,
     "user": {
      "displayName": "Miguel Neves",
      "userId": "01323576189800675186"
     },
     "user_tz": 0
    },
    "id": "QhsEQy32aLdD",
    "outputId": "b3b40bb8-d9f6-4dd9-b5c8-106fd3b584d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Total Epochs -> 10\n",
      "Load all datasets successfully.\n",
      "Build `rrdbnet_x4` model successfully.\n",
      "Define all loss functions successfully.\n",
      "Check whether to load pretrained d model weights...\n",
      "Loaded `./results/Discriminator/Discrminator_x4-DFO2K-e74d7ca1.pth.tar` pretrained model weights successfully.\n",
      "Check whether to load pretrained g model weights...\n",
      "Loaded `./results/RRDBNet_x4/RRDBNet_x4-DFO2K-2e2a91f4.pth.tar` pretrained model weights successfully.\n",
      "Define all optimizer functions successfully.\n",
      "Define all optimizer scheduler functions successfully.\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "2023/03/21 15:31:34 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Active run_id: 2f4d7eef4e784292892a39599f91f03c\n",
      "Training\n",
      "Epoch: [1][  1/211]\tTime  2.267 ( 2.267)\tData  0.000 ( 0.000)\tPixel loss 0.000234 (0.000234)\tContent loss 1.230294 (1.230294)\tAdversarial loss 0.331025 (0.331025)\tD(GT)  0.000 ( 0.000)\tD(SR)  0.000 ( 0.000)\n",
      "Epoch: [1][101/211]\tTime  0.236 ( 0.263)\tData  0.000 ( 0.000)\tPixel loss 0.000418 (0.000293)\tContent loss 1.087008 (1.012662)\tAdversarial loss 0.098711 (0.063264)\tD(GT)  0.000 ( 0.000)\tD(SR)  0.000 ( 0.000)\n",
      "Epoch: [1][201/211]\tTime  0.238 ( 0.253)\tData  0.000 ( 0.000)\tPixel loss 0.000229 (0.000276)\tContent loss 0.873789 (0.942434)\tAdversarial loss 0.023458 (0.045047)\tD(GT)  1.000 ( 0.379)\tD(SR)  1.000 ( 0.366)\n",
      "Valid: [  1/519]\tTime  1.520 ( 1.520)\tPSNR 30.56 (30.56)\tSSIM 0.9144 (0.9144)\tNIQE 6.42 (6.42)\tLPIPS 0.0610 (0.0610)\n",
      "Valid: [101/519]\tTime  0.074 ( 0.087)\tPSNR 23.97 (28.98)\tSSIM 0.8270 (0.8734)\tNIQE 5.79 (9.08)\tLPIPS 0.0816 (0.0672)\n",
      "Valid: [201/519]\tTime  0.081 ( 0.080)\tPSNR 30.70 (29.39)\tSSIM 0.9001 (0.8801)\tNIQE 8.02 (9.37)\tLPIPS 0.0443 (0.0646)\n",
      "Valid: [301/519]\tTime  0.074 ( 0.078)\tPSNR 30.40 (29.21)\tSSIM 0.9254 (0.8789)\tNIQE 8.38 (9.50)\tLPIPS 0.0369 (0.0647)\n",
      "Valid: [401/519]\tTime  0.072 ( 0.077)\tPSNR 24.45 (29.01)\tSSIM 0.7772 (0.8753)\tNIQE 6.08 (9.46)\tLPIPS 0.0924 (0.0665)\n",
      "Valid: [501/519]\tTime  0.078 ( 0.076)\tPSNR 22.73 (28.93)\tSSIM 0.8045 (0.8736)\tNIQE 5.39 (9.43)\tLPIPS 0.0915 (0.0670)\n",
      " * Time 0.08 PSNR 28.89 SSIM 0.87 NIQE 9.44 LPIPS 0.07\n",
      "\n",
      "\n",
      "\n",
      "Logging epoch data...\n",
      "Finished Logging\n",
      "\n",
      "Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Saving\n",
      "Training\n",
      "Epoch: [2][  1/211]\tTime  0.308 ( 0.308)\tData  0.000 ( 0.000)\tPixel loss 0.000246 (0.000246)\tContent loss 0.919975 (0.919975)\tAdversarial loss 0.010529 (0.010529)\tD(GT)  1.000 ( 1.000)\tD(SR)  0.999 ( 0.999)\n",
      "Epoch: [2][101/211]\tTime  0.243 ( 0.244)\tData  0.000 ( 0.000)\tPixel loss 0.000326 (0.000251)\tContent loss 0.879672 (0.816349)\tAdversarial loss 0.048472 (0.023195)\tD(GT)  0.000 ( 0.408)\tD(SR)  0.000 ( 0.296)\n",
      "Epoch: [2][201/211]\tTime  0.237 ( 0.245)\tData  0.000 ( 0.000)\tPixel loss 0.000204 (0.000243)\tContent loss 0.747880 (0.813557)\tAdversarial loss 0.025175 (0.028038)\tD(GT)  0.000 ( 0.247)\tD(SR)  0.000 ( 0.156)\n",
      "Valid: [  1/519]\tTime  0.088 ( 0.088)\tPSNR 29.55 (29.55)\tSSIM 0.8838 (0.8838)\tNIQE 6.19 (6.19)\tLPIPS 0.0797 (0.0797)\n",
      "Valid: [101/519]\tTime  0.073 ( 0.075)\tPSNR 22.70 (28.06)\tSSIM 0.8018 (0.8516)\tNIQE 6.95 (9.70)\tLPIPS 0.1093 (0.0917)\n",
      "Valid: [201/519]\tTime  0.073 ( 0.075)\tPSNR 30.11 (28.49)\tSSIM 0.8845 (0.8590)\tNIQE 7.79 (9.93)\tLPIPS 0.0537 (0.0888)\n",
      "Valid: [301/519]\tTime  0.072 ( 0.075)\tPSNR 30.28 (28.33)\tSSIM 0.9168 (0.8583)\tNIQE 7.82 (10.13)\tLPIPS 0.0400 (0.0886)\n",
      "Valid: [401/519]\tTime  0.075 ( 0.075)\tPSNR 20.60 (28.08)\tSSIM 0.7049 (0.8539)\tNIQE 8.45 (10.08)\tLPIPS 0.1756 (0.0915)\n",
      "Valid: [501/519]\tTime  0.072 ( 0.075)\tPSNR 22.15 (28.00)\tSSIM 0.7898 (0.8520)\tNIQE 5.20 (10.09)\tLPIPS 0.1017 (0.0922)\n",
      " * Time 0.07 PSNR 27.95 SSIM 0.85 NIQE 10.09 LPIPS 0.09\n",
      "\n",
      "\n",
      "\n",
      "Logging epoch data...\n",
      "Finished Logging\n",
      "\n",
      "Was not the best\n",
      "Training\n",
      "Epoch: [3][  1/211]\tTime  0.260 ( 0.260)\tData  0.000 ( 0.000)\tPixel loss 0.000312 (0.000312)\tContent loss 0.842959 (0.842959)\tAdversarial loss 0.042907 (0.042907)\tD(GT)  1.000 ( 1.000)\tD(SR)  0.990 ( 0.990)\n",
      "Epoch: [3][101/211]\tTime  0.241 ( 0.243)\tData  0.000 ( 0.000)\tPixel loss 0.000320 (0.000250)\tContent loss 0.798619 (0.813734)\tAdversarial loss 0.014054 (0.022993)\tD(GT)  0.000 ( 0.457)\tD(SR)  0.000 ( 0.433)\n",
      "Epoch: [3][201/211]\tTime  0.242 ( 0.241)\tData  0.000 ( 0.000)\tPixel loss 0.000183 (0.000242)\tContent loss 0.738194 (0.799478)\tAdversarial loss 0.010167 (0.024205)\tD(GT)  0.000 ( 0.232)\tD(SR)  0.000 ( 0.217)\n",
      "Valid: [  1/519]\tTime  0.084 ( 0.084)\tPSNR 30.48 (30.48)\tSSIM 0.9009 (0.9009)\tNIQE 6.29 (6.29)\tLPIPS 0.0747 (0.0747)\n",
      "Valid: [101/519]\tTime  0.074 ( 0.075)\tPSNR 23.87 (28.96)\tSSIM 0.8223 (0.8668)\tNIQE 6.15 (9.38)\tLPIPS 0.0841 (0.0707)\n",
      "Valid: [201/519]\tTime  0.083 ( 0.075)\tPSNR 30.44 (29.38)\tSSIM 0.8863 (0.8737)\tNIQE 8.28 (9.69)\tLPIPS 0.0537 (0.0682)\n",
      "Valid: [301/519]\tTime  0.074 ( 0.075)\tPSNR 30.59 (29.21)\tSSIM 0.9191 (0.8729)\tNIQE 8.34 (9.88)\tLPIPS 0.0406 (0.0682)\n",
      "Valid: [401/519]\tTime  0.074 ( 0.075)\tPSNR 24.07 (28.99)\tSSIM 0.7590 (0.8691)\tNIQE 6.93 (9.83)\tLPIPS 0.0898 (0.0698)\n",
      "Valid: [501/519]\tTime  0.078 ( 0.074)\tPSNR 22.85 (28.91)\tSSIM 0.8073 (0.8675)\tNIQE 5.23 (9.83)\tLPIPS 0.0902 (0.0702)\n",
      " * Time 0.07 PSNR 28.87 SSIM 0.87 NIQE 9.83 LPIPS 0.07\n",
      "\n",
      "\n",
      "\n",
      "Logging epoch data...\n",
      "Finished Logging\n",
      "\n",
      "Was not the best\n",
      "Training\n",
      "Epoch: [4][  1/211]\tTime  0.265 ( 0.265)\tData  0.000 ( 0.000)\tPixel loss 0.000268 (0.000268)\tContent loss 0.905347 (0.905347)\tAdversarial loss 0.051362 (0.051362)\tD(GT)  0.000 ( 0.000)\tD(SR)  0.000 ( 0.000)\n",
      "Epoch: [4][101/211]\tTime  0.239 ( 0.246)\tData  0.000 ( 0.000)\tPixel loss 0.000227 (0.000244)\tContent loss 0.753666 (0.795383)\tAdversarial loss 0.063201 (0.024469)\tD(GT)  0.000 ( 0.050)\tD(SR)  0.000 ( 0.008)\n",
      "Epoch: [4][201/211]\tTime  0.240 ( 0.245)\tData  0.000 ( 0.000)\tPixel loss 0.000262 (0.000245)\tContent loss 0.811902 (0.795488)\tAdversarial loss 0.020883 (0.025220)\tD(GT)  0.131 ( 0.098)\tD(SR)  0.002 ( 0.041)\n",
      "Valid: [  1/519]\tTime  0.092 ( 0.092)\tPSNR 30.43 (30.43)\tSSIM 0.9072 (0.9072)\tNIQE 6.44 (6.44)\tLPIPS 0.0687 (0.0687)\n",
      "Valid: [101/519]\tTime  0.073 ( 0.074)\tPSNR 23.61 (28.89)\tSSIM 0.8117 (0.8633)\tNIQE 6.63 (9.45)\tLPIPS 0.0845 (0.0694)\n",
      "Valid: [201/519]\tTime  0.074 ( 0.074)\tPSNR 30.38 (29.31)\tSSIM 0.8901 (0.8707)\tNIQE 7.80 (9.77)\tLPIPS 0.0501 (0.0669)\n",
      "Valid: [301/519]\tTime  0.072 ( 0.074)\tPSNR 30.45 (29.13)\tSSIM 0.9213 (0.8696)\tNIQE 8.64 (9.95)\tLPIPS 0.0398 (0.0669)\n",
      "Valid: [401/519]\tTime  0.074 ( 0.074)\tPSNR 23.81 (28.92)\tSSIM 0.7476 (0.8654)\tNIQE 7.04 (9.92)\tLPIPS 0.0888 (0.0688)\n",
      "Valid: [501/519]\tTime  0.077 ( 0.074)\tPSNR 22.54 (28.84)\tSSIM 0.7922 (0.8635)\tNIQE 5.65 (9.91)\tLPIPS 0.0923 (0.0691)\n",
      " * Time 0.07 PSNR 28.79 SSIM 0.86 NIQE 9.91 LPIPS 0.07\n",
      "\n",
      "\n",
      "\n",
      "Logging epoch data...\n",
      "Finished Logging\n",
      "\n",
      "Was not the best\n",
      "Training\n",
      "Epoch: [5][  1/211]\tTime  0.262 ( 0.262)\tData  0.000 ( 0.000)\tPixel loss 0.000189 (0.000189)\tContent loss 0.698626 (0.698626)\tAdversarial loss 0.015563 (0.015563)\tD(GT)  1.000 ( 1.000)\tD(SR)  0.986 ( 0.986)\n",
      "Epoch: [5][101/211]\tTime  0.243 ( 0.244)\tData  0.000 ( 0.000)\tPixel loss 0.000198 (0.000240)\tContent loss 0.850736 (0.783756)\tAdversarial loss 0.005748 (0.026183)\tD(GT)  0.000 ( 0.590)\tD(SR)  0.000 ( 0.434)\n",
      "Epoch: [5][201/211]\tTime  0.244 ( 0.244)\tData  0.000 ( 0.000)\tPixel loss 0.000257 (0.000235)\tContent loss 0.837246 (0.779465)\tAdversarial loss 0.031153 (0.025282)\tD(GT)  0.000 ( 0.407)\tD(SR)  0.000 ( 0.277)\n",
      "Valid: [  1/519]\tTime  0.094 ( 0.094)\tPSNR 31.02 (31.02)\tSSIM 0.9114 (0.9114)\tNIQE 6.16 (6.16)\tLPIPS 0.0636 (0.0636)\n",
      "Valid: [101/519]\tTime  0.073 ( 0.074)\tPSNR 24.40 (29.33)\tSSIM 0.8355 (0.8747)\tNIQE 6.07 (9.43)\tLPIPS 0.0806 (0.0663)\n",
      "Valid: [201/519]\tTime  0.073 ( 0.074)\tPSNR 30.61 (29.76)\tSSIM 0.8916 (0.8816)\tNIQE 7.77 (9.74)\tLPIPS 0.0482 (0.0636)\n",
      "Valid: [301/519]\tTime  0.076 ( 0.074)\tPSNR 30.78 (29.59)\tSSIM 0.9235 (0.8808)\tNIQE 8.04 (9.92)\tLPIPS 0.0380 (0.0637)\n",
      "Valid: [401/519]\tTime  0.080 ( 0.074)\tPSNR 24.51 (29.39)\tSSIM 0.7719 (0.8775)\tNIQE 6.16 (9.88)\tLPIPS 0.0797 (0.0650)\n",
      "Valid: [501/519]\tTime  0.077 ( 0.074)\tPSNR 23.32 (29.31)\tSSIM 0.8218 (0.8759)\tNIQE 5.42 (9.86)\tLPIPS 0.0840 (0.0653)\n",
      " * Time 0.07 PSNR 29.27 SSIM 0.88 NIQE 9.86 LPIPS 0.07\n",
      "\n",
      "\n",
      "\n",
      "Logging epoch data...\n",
      "Finished Logging\n",
      "\n",
      "Saving best model...\n",
      "Finished Saving\n",
      "Training\n",
      "Epoch: [6][  1/211]\tTime  0.275 ( 0.275)\tData  0.000 ( 0.000)\tPixel loss 0.000196 (0.000196)\tContent loss 0.669980 (0.669980)\tAdversarial loss 0.010374 (0.010374)\tD(GT)  1.000 ( 1.000)\tD(SR)  1.000 ( 1.000)\n",
      "Epoch: [6][101/211]\tTime  0.248 ( 0.242)\tData  0.000 ( 0.000)\tPixel loss 0.000260 (0.000233)\tContent loss 0.835478 (0.774637)\tAdversarial loss 0.034476 (0.020070)\tD(GT)  0.978 ( 0.565)\tD(SR)  0.043 ( 0.470)\n",
      "Epoch: [6][201/211]\tTime  0.251 ( 0.243)\tData  0.000 ( 0.000)\tPixel loss 0.000284 (0.000232)\tContent loss 0.801215 (0.775004)\tAdversarial loss 0.029730 (0.021386)\tD(GT)  0.000 ( 0.295)\tD(SR)  0.000 ( 0.238)\n",
      "Valid: [  1/519]\tTime  0.091 ( 0.091)\tPSNR 30.91 (30.91)\tSSIM 0.9114 (0.9114)\tNIQE 7.20 (7.20)\tLPIPS 0.0540 (0.0540)\n",
      "Valid: [101/519]\tTime  0.072 ( 0.075)\tPSNR 24.61 (29.38)\tSSIM 0.8424 (0.8781)\tNIQE 6.29 (9.53)\tLPIPS 0.0762 (0.0606)\n",
      "Valid: [201/519]\tTime  0.078 ( 0.075)\tPSNR 30.58 (29.80)\tSSIM 0.8907 (0.8847)\tNIQE 8.06 (9.82)\tLPIPS 0.0428 (0.0579)\n",
      "Valid: [301/519]\tTime  0.075 ( 0.075)\tPSNR 30.88 (29.64)\tSSIM 0.9250 (0.8840)\tNIQE 8.08 (10.00)\tLPIPS 0.0331 (0.0582)\n",
      "Valid: [401/519]\tTime  0.080 ( 0.075)\tPSNR 24.50 (29.44)\tSSIM 0.7756 (0.8808)\tNIQE 6.38 (9.95)\tLPIPS 0.0716 (0.0596)\n",
      "Valid: [501/519]\tTime  0.074 ( 0.075)\tPSNR 23.58 (29.36)\tSSIM 0.8305 (0.8793)\tNIQE 5.65 (9.93)\tLPIPS 0.0822 (0.0601)\n",
      " * Time 0.08 PSNR 29.32 SSIM 0.88 NIQE 9.93 LPIPS 0.06\n",
      "\n",
      "\n",
      "\n",
      "Logging epoch data...\n",
      "Finished Logging\n",
      "\n",
      "Saving best model...\n",
      "Finished Saving\n",
      "Training\n",
      "Epoch: [7][  1/211]\tTime  0.411 ( 0.411)\tData  0.000 ( 0.000)\tPixel loss 0.000265 (0.000265)\tContent loss 0.742134 (0.742134)\tAdversarial loss 0.017654 (0.017654)\tD(GT)  0.000 ( 0.000)\tD(SR)  0.000 ( 0.000)\n",
      "Epoch: [7][101/211]\tTime  0.252 ( 0.247)\tData  0.000 ( 0.000)\tPixel loss 0.000201 (0.000240)\tContent loss 0.716892 (0.775020)\tAdversarial loss 0.006118 (0.021453)\tD(GT)  0.000 ( 0.000)\tD(SR)  0.000 ( 0.000)\n",
      "Epoch: [7][201/211]\tTime  0.254 ( 0.247)\tData  0.000 ( 0.000)\tPixel loss 0.000217 (0.000234)\tContent loss 0.797750 (0.769625)\tAdversarial loss 0.014918 (0.022383)\tD(GT)  0.000 ( 0.000)\tD(SR)  0.000 ( 0.000)\n",
      "Valid: [  1/519]\tTime  0.086 ( 0.086)\tPSNR 31.00 (31.00)\tSSIM 0.9110 (0.9110)\tNIQE 7.17 (7.17)\tLPIPS 0.0531 (0.0531)\n",
      "Valid: [101/519]\tTime  0.076 ( 0.075)\tPSNR 24.38 (29.18)\tSSIM 0.8350 (0.8728)\tNIQE 6.28 (9.26)\tLPIPS 0.0743 (0.0593)\n",
      "Valid: [201/519]\tTime  0.074 ( 0.075)\tPSNR 30.34 (29.59)\tSSIM 0.8872 (0.8796)\tNIQE 7.43 (9.59)\tLPIPS 0.0405 (0.0567)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [301/519]\tTime  0.076 ( 0.075)\tPSNR 30.65 (29.43)\tSSIM 0.9206 (0.8788)\tNIQE 7.65 (9.75)\tLPIPS 0.0324 (0.0570)\n",
      "Valid: [401/519]\tTime  0.076 ( 0.075)\tPSNR 24.29 (29.24)\tSSIM 0.7663 (0.8754)\tNIQE 6.31 (9.70)\tLPIPS 0.0701 (0.0582)\n",
      "Valid: [501/519]\tTime  0.074 ( 0.075)\tPSNR 23.41 (29.16)\tSSIM 0.8221 (0.8739)\tNIQE 5.74 (9.67)\tLPIPS 0.0738 (0.0586)\n",
      " * Time 0.08 PSNR 29.12 SSIM 0.87 NIQE 9.67 LPIPS 0.06\n",
      "\n",
      "\n",
      "\n",
      "Logging epoch data...\n",
      "Finished Logging\n",
      "\n",
      "Saving best model...\n",
      "Finished Saving\n",
      "Training\n",
      "Epoch: [8][  1/211]\tTime  0.279 ( 0.279)\tData  0.000 ( 0.000)\tPixel loss 0.000144 (0.000144)\tContent loss 0.622071 (0.622071)\tAdversarial loss 0.033756 (0.033756)\tD(GT)  0.000 ( 0.000)\tD(SR)  0.000 ( 0.000)\n",
      "Epoch: [8][101/211]\tTime  0.249 ( 0.247)\tData  0.000 ( 0.000)\tPixel loss 0.000173 (0.000227)\tContent loss 0.661598 (0.763354)\tAdversarial loss 0.045723 (0.024454)\tD(GT)  0.000 ( 0.000)\tD(SR)  0.000 ( 0.000)\n",
      "Epoch: [8][201/211]\tTime  0.251 ( 0.248)\tData  0.000 ( 0.000)\tPixel loss 0.000273 (0.000230)\tContent loss 0.883657 (0.769774)\tAdversarial loss 0.019789 (0.023988)\tD(GT)  0.000 ( 0.000)\tD(SR)  0.000 ( 0.000)\n",
      "Valid: [  1/519]\tTime  0.088 ( 0.088)\tPSNR 31.08 (31.08)\tSSIM 0.9138 (0.9138)\tNIQE 6.90 (6.90)\tLPIPS 0.0542 (0.0542)\n",
      "Valid: [101/519]\tTime  0.075 ( 0.075)\tPSNR 24.32 (29.27)\tSSIM 0.8354 (0.8748)\tNIQE 6.51 (8.99)\tLPIPS 0.0754 (0.0585)\n",
      "Valid: [201/519]\tTime  0.076 ( 0.075)\tPSNR 30.38 (29.68)\tSSIM 0.8895 (0.8815)\tNIQE 7.52 (9.31)\tLPIPS 0.0402 (0.0561)\n",
      "Valid: [301/519]\tTime  0.074 ( 0.075)\tPSNR 30.68 (29.51)\tSSIM 0.9231 (0.8805)\tNIQE 7.48 (9.47)\tLPIPS 0.0312 (0.0562)\n",
      "Valid: [401/519]\tTime  0.077 ( 0.075)\tPSNR 24.31 (29.31)\tSSIM 0.7694 (0.8772)\tNIQE 6.43 (9.42)\tLPIPS 0.0724 (0.0576)\n",
      "Valid: [501/519]\tTime  0.071 ( 0.075)\tPSNR 23.33 (29.23)\tSSIM 0.8216 (0.8757)\tNIQE 6.07 (9.38)\tLPIPS 0.0729 (0.0580)\n",
      " * Time 0.08 PSNR 29.19 SSIM 0.87 NIQE 9.38 LPIPS 0.06\n",
      "\n",
      "\n",
      "\n",
      "Logging epoch data...\n",
      "Finished Logging\n",
      "\n",
      "Saving best model...\n",
      "Finished Saving\n",
      "Training\n",
      "Epoch: [9][  1/211]\tTime  0.277 ( 0.277)\tData  0.000 ( 0.000)\tPixel loss 0.000194 (0.000194)\tContent loss 0.726033 (0.726033)\tAdversarial loss 0.030719 (0.030719)\tD(GT)  0.000 ( 0.000)\tD(SR)  0.000 ( 0.000)\n",
      "Epoch: [9][101/211]\tTime  0.240 ( 0.243)\tData  0.000 ( 0.000)\tPixel loss 0.000267 (0.000238)\tContent loss 0.890849 (0.775688)\tAdversarial loss 0.024445 (0.025438)\tD(GT)  0.000 ( 0.000)\tD(SR)  0.000 ( 0.000)\n",
      "Epoch: [9][201/211]\tTime  0.243 ( 0.244)\tData  0.000 ( 0.000)\tPixel loss 0.000180 (0.000235)\tContent loss 0.718312 (0.770242)\tAdversarial loss 0.017345 (0.024760)\tD(GT)  0.000 ( 0.000)\tD(SR)  0.000 ( 0.000)\n",
      "Valid: [  1/519]\tTime  0.087 ( 0.087)\tPSNR 31.20 (31.20)\tSSIM 0.9137 (0.9137)\tNIQE 6.77 (6.77)\tLPIPS 0.0524 (0.0524)\n",
      "Valid: [101/519]\tTime  0.076 ( 0.075)\tPSNR 24.33 (29.34)\tSSIM 0.8333 (0.8721)\tNIQE 6.26 (8.87)\tLPIPS 0.0734 (0.0578)\n",
      "Valid: [201/519]\tTime  0.071 ( 0.075)\tPSNR 30.45 (29.76)\tSSIM 0.8885 (0.8790)\tNIQE 7.33 (9.18)\tLPIPS 0.0400 (0.0554)\n",
      "Valid: [301/519]\tTime  0.073 ( 0.075)\tPSNR 30.90 (29.59)\tSSIM 0.9240 (0.8780)\tNIQE 7.41 (9.33)\tLPIPS 0.0312 (0.0556)\n",
      "Valid: [401/519]\tTime  0.076 ( 0.075)\tPSNR 24.12 (29.38)\tSSIM 0.7615 (0.8745)\tNIQE 6.15 (9.28)\tLPIPS 0.0706 (0.0570)\n",
      "Valid: [501/519]\tTime  0.074 ( 0.075)\tPSNR 23.27 (29.30)\tSSIM 0.8174 (0.8729)\tNIQE 5.72 (9.24)\tLPIPS 0.0706 (0.0574)\n",
      " * Time 0.08 PSNR 29.26 SSIM 0.87 NIQE 9.24 LPIPS 0.06\n",
      "\n",
      "\n",
      "\n",
      "Logging epoch data...\n",
      "Finished Logging\n",
      "\n",
      "Saving best model...\n",
      "Finished Saving\n",
      "Training\n",
      "Epoch: [10][  1/211]\tTime  0.273 ( 0.273)\tData  0.000 ( 0.000)\tPixel loss 0.000232 (0.000232)\tContent loss 0.807323 (0.807323)\tAdversarial loss 0.018796 (0.018796)\tD(GT)  0.000 ( 0.000)\tD(SR)  0.000 ( 0.000)\n",
      "Epoch: [10][101/211]\tTime  0.250 ( 0.246)\tData  0.000 ( 0.000)\tPixel loss 0.000130 (0.000234)\tContent loss 0.464491 (0.773939)\tAdversarial loss 0.014007 (0.022379)\tD(GT)  0.000 ( 0.000)\tD(SR)  0.000 ( 0.000)\n",
      "Epoch: [10][201/211]\tTime  0.247 ( 0.248)\tData  0.000 ( 0.000)\tPixel loss 0.000264 (0.000236)\tContent loss 0.754155 (0.773593)\tAdversarial loss 0.014918 (0.023486)\tD(GT)  0.000 ( 0.000)\tD(SR)  0.000 ( 0.000)\n",
      "Valid: [  1/519]\tTime  0.093 ( 0.093)\tPSNR 31.07 (31.07)\tSSIM 0.9126 (0.9126)\tNIQE 7.08 (7.08)\tLPIPS 0.0547 (0.0547)\n",
      "Valid: [101/519]\tTime  0.075 ( 0.076)\tPSNR 24.31 (29.38)\tSSIM 0.8337 (0.8740)\tNIQE 6.35 (8.97)\tLPIPS 0.0711 (0.0564)\n",
      "Valid: [201/519]\tTime  0.074 ( 0.076)\tPSNR 30.39 (29.80)\tSSIM 0.8885 (0.8808)\tNIQE 7.54 (9.28)\tLPIPS 0.0399 (0.0542)\n",
      "Valid: [301/519]\tTime  0.072 ( 0.075)\tPSNR 30.88 (29.63)\tSSIM 0.9238 (0.8797)\tNIQE 7.38 (9.45)\tLPIPS 0.0313 (0.0543)\n",
      "Valid: [401/519]\tTime  0.075 ( 0.075)\tPSNR 24.24 (29.43)\tSSIM 0.7668 (0.8764)\tNIQE 6.51 (9.41)\tLPIPS 0.0698 (0.0557)\n",
      "Valid: [501/519]\tTime  0.072 ( 0.075)\tPSNR 23.19 (29.35)\tSSIM 0.8154 (0.8748)\tNIQE 5.73 (9.37)\tLPIPS 0.0697 (0.0560)\n",
      " * Time 0.08 PSNR 29.30 SSIM 0.87 NIQE 9.37 LPIPS 0.06\n",
      "\n",
      "\n",
      "\n",
      "Logging epoch data...\n",
      "Finished Logging\n",
      "\n",
      "Saving best model...\n",
      "Finished Saving\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2021 Dakewe Biotech Corporation. All Rights Reserved.\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#   you may not use this file except in compliance with the License.\n",
    "#   You may obtain a copy of the License at\n",
    "#\n",
    "#       http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.cuda import amp\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim.swa_utils import AveragedModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import mlflow\n",
    "\n",
    "import esrgan_config\n",
    "\n",
    "\n",
    "import model\n",
    "from dataset import CUDAPrefetcher, TrainValidImageDataset, TestImageDataset\n",
    "from image_quality_assessment import PSNR, SSIM, NIQE\n",
    "from lpips import LPIPS\n",
    "from utils import load_state_dict, make_directory, save_checkpoint, AverageMeter, ProgressMeter\n",
    "\n",
    "model_names = sorted(\n",
    "    name for name in model.__dict__ if\n",
    "    name.islower() and not name.startswith(\"__\") and callable(model.__dict__[name]))\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Initialize the number of training epochs\n",
    "    start_epoch = 0\n",
    "\n",
    "    # Initialize training to generate network evaluation indicators\n",
    "    best_psnr = 0.0\n",
    "    best_ssim = 0.0\n",
    "\n",
    "    train_prefetcher, valid_prefetcher = load_dataset()\n",
    "    print(\"Load all datasets successfully.\")\n",
    "\n",
    "    d_model, g_model, ema_g_model = build_model()\n",
    "    print(f\"Build `{esrgan_config.g_arch_name}` model successfully.\")\n",
    "\n",
    "    pixel_criterion, content_criterion, adversarial_criterion = define_loss()\n",
    "    print(\"Define all loss functions successfully.\")\n",
    "\n",
    "    # Start MLFlow Tracking\n",
    "    try:\n",
    "        mlflow.set_experiment(esrgan_config.experience_name)\n",
    "    except:\n",
    "        experiment_id= mlflow.create_experiment(esrgan_config.experience_name)\n",
    "        print(\"New Experiment created with name: \" + esrgan_config.experience_name + \" and ID: \" + str(experiment_id))\n",
    "    \n",
    "\n",
    "    \n",
    "    print(\"Check whether to load pretrained d model weights...\")\n",
    "    if esrgan_config.pretrained_d_model_weights_path:\n",
    "        #d_model = mlflow.pytorch.load_model(esrgan_config.pretrained_d_model_weights_path)\n",
    "        d_model = load_state_dict(d_model, esrgan_config.pretrained_d_model_weights_path)\n",
    "        print(f\"Loaded `{esrgan_config.pretrained_d_model_weights_path}` pretrained model weights successfully.\")\n",
    "    else:\n",
    "        print(\"Pretrained d model weights not found.\")\n",
    "\n",
    "    print(\"Check whether to load pretrained g model weights...\")\n",
    "    if esrgan_config.pretrained_g_model_weights_path:\n",
    "        #g_model = mlflow.pytorch.load_model(esrgan_config.pretrained_g_model_weights_path)\n",
    "        g_model = load_state_dict(g_model, esrgan_config.pretrained_g_model_weights_path)\n",
    "        print(f\"Loaded `{esrgan_config.pretrained_g_model_weights_path}` pretrained model weights successfully.\")\n",
    "    else:\n",
    "        print(\"Pretrained g model weights not found.\")\n",
    "\n",
    "    # Define optimizers\n",
    "    d_optimizer, g_optimizer = define_optimizer(d_model, g_model)\n",
    "    print(\"Define all optimizer functions successfully.\")\n",
    "\n",
    "    d_scheduler, g_scheduler = define_scheduler(d_optimizer, g_optimizer)\n",
    "    print(\"Define all optimizer scheduler functions successfully.\")\n",
    "\n",
    "    '''\n",
    "    print(\"Check whether the pretrained d model is restored...\")\n",
    "    if esrgan_config.resume_d_model_weights_path:\n",
    "        d_model, _, start_epoch, best_psnr, best_ssim, optimizer, scheduler = load_state_dict(\n",
    "            d_model,\n",
    "            esrgan_config.resume_d_model_weights_path,\n",
    "            optimizer=d_optimizer,\n",
    "            scheduler=d_scheduler,\n",
    "            load_mode=\"resume\")\n",
    "        print(\"Loaded pretrained model weights.\")\n",
    "    else:\n",
    "        print(\"Resume training d model not found. Start training from scratch.\")\n",
    "\n",
    "    print(\"Check whether the pretrained g model is restored...\")\n",
    "    if esrgan_config.resume_g_model_weights_path:\n",
    "        lsrresnet_model, ema_lsrresnet_model, start_epoch, best_psnr, best_ssim, optimizer, scheduler = load_state_dict(\n",
    "            g_model,\n",
    "            esrgan_config.resume_g_model_weights_path,\n",
    "            ema_model=ema_g_model,\n",
    "            optimizer=g_optimizer,\n",
    "            scheduler=g_scheduler,\n",
    "            load_mode=\"resume\")\n",
    "        print(\"Loaded pretrained model weights.\")\n",
    "    else:\n",
    "        print(\"Resume training g model not found. Start training from scratch.\")\n",
    "    '''\n",
    "\n",
    "    # Create a experiment results\n",
    "    samples_dir = os.path.join(\"samples\", esrgan_config.exp_name)\n",
    "    results_dir = os.path.join(\"results\", esrgan_config.exp_name)\n",
    "    make_directory(samples_dir)\n",
    "    make_directory(results_dir)\n",
    "\n",
    "    # Create training process log file\n",
    "    writer = SummaryWriter(os.path.join(\"samples\", \"logs\", esrgan_config.exp_name))\n",
    "\n",
    "\n",
    "    # Initialize the gradient scaler\n",
    "    scaler = amp.GradScaler()\n",
    "\n",
    "    # Create an IQA evaluation model\n",
    "    psnr_model = PSNR(esrgan_config.upscale_factor, esrgan_config.only_test_y_channel)\n",
    "    ssim_model = SSIM(esrgan_config.upscale_factor, esrgan_config.only_test_y_channel)\n",
    "    niqe_model = NIQE(esrgan_config.upscale_factor, esrgan_config.niqe_model_path)\n",
    "    lpips_model = LPIPS(net=esrgan_config.lpips_net)\n",
    "\n",
    "    # Transfer the IQA model to the specified device\n",
    "    psnr_model = psnr_model.to(device=esrgan_config.device)\n",
    "    ssim_model = ssim_model.to(device=esrgan_config.device)\n",
    "    niqe_model = niqe_model.to(device=esrgan_config.device, non_blocking=True)\n",
    "    lpips_model = lpips_model.to(device=esrgan_config.device, non_blocking=True)\n",
    "\n",
    "\n",
    "    best_lpips_metrics = 1.0\n",
    "\n",
    "    # Start MLflow run & log parameters \n",
    "    try:\n",
    "      mlflow.start_run(run_name=esrgan_config.run_name, tags=esrgan_config.tags, description=esrgan_config.description)\n",
    "    except: # If last session was not ended\n",
    "      mlflow.end_run()\n",
    "      mlflow.start_run(run_name=esrgan_config.run_name, tags=esrgan_config.tags, description=esrgan_config.description)\n",
    "    \n",
    "    run = mlflow.active_run()\n",
    "    print(\"Active run_id: {}\".format(run.info.run_id))\n",
    "\n",
    "    #mlflow.log_params({'exp_name':esrgan_config.exp_name,'d_arch_name':esrgan_config.d_arch_name,'g_arch_name':esrgan_config.g_arch_name,'in_channels':esrgan_config.in_channels,'out_channels':esrgan_config.out_channels,'channels':esrgan_config.channels,'growth_channels':esrgan_config.growth_channels,'num_blocks':esrgan_config.num_blocks,'upscale_factor':esrgan_config.upscale_factor,'gt_image_size':esrgan_config.gt_image_size,'batch_size':esrgan_config.batch_size,'train_gt_images_dir':esrgan_config.train_gt_images_dir,'test_gt_images_dir':esrgan_config.test_gt_images_dir,'test_lr_images_dir':esrgan_config.test_lr_images_dir,'pretrained_d_model_weights_path':esrgan_config.pretrained_d_model_weights_path,'pretrained_g_model_weights_path':esrgan_config.pretrained_g_model_weights_path,'resume_d_model_weights_path':esrgan_config.resume_d_model_weights_path,'resume_g_model_weights_path':esrgan_config.resume_g_model_weights_path,'epochs':esrgan_config.epochs,'pixel_weight':esrgan_config.pixel_weight,'content_weight':esrgan_config.content_weight,'adversarial_weight':esrgan_config.adversarial_weight,'feature_model_extractor_node':esrgan_config.feature_model_extractor_node,'feature_model_normalize_mean':esrgan_config.feature_model_normalize_mean,'feature_model_normalize_std':esrgan_config.feature_model_normalize_std,'model_lr':esrgan_config.model_lr,'model_betas':esrgan_config.model_betas,'model_eps':esrgan_config.model_eps,'model_weight_decay':esrgan_config.model_weight_decay,'model_ema_decay':esrgan_config.model_ema_decay,'lr_scheduler_milestones':esrgan_config.lr_scheduler_milestones,'lr_scheduler_gamma':esrgan_config.lr_scheduler_gamma,'lpips_net':esrgan_config.lpips_net,'niqe_model_path':esrgan_config.niqe_model_path})\n",
    "    mlflow.log_params({'exp_name':esrgan_config.exp_name,'d_arch_name':esrgan_config.d_arch_name,'g_arch_name':esrgan_config.g_arch_name,'in_channels':esrgan_config.in_channels,'out_channels':esrgan_config.out_channels,'channels':esrgan_config.channels,'growth_channels':esrgan_config.growth_channels,'num_blocks':esrgan_config.num_blocks,'upscale_factor':esrgan_config.upscale_factor,'gt_image_size':esrgan_config.gt_image_size,'batch_size':esrgan_config.batch_size,'train_gt_images_dir':esrgan_config.train_gt_images_dir,'valid_gt_images_dir':esrgan_config.valid_gt_images_dir,\n",
    "                       'pretrained_d_model_weights_path':esrgan_config.pretrained_d_model_weights_path,'pretrained_g_model_weights_path':esrgan_config.pretrained_g_model_weights_path,'resume_d_model_weights_path':esrgan_config.resume_d_model_weights_path,'resume_g_model_weights_path':esrgan_config.resume_g_model_weights_path,'epochs':esrgan_config.epochs,'pixel_weight':esrgan_config.pixel_weight,'content_weight':esrgan_config.content_weight,'adversarial_weight':esrgan_config.adversarial_weight,'feature_model_extractor_node':esrgan_config.feature_model_extractor_node,'feature_model_normalize_mean':esrgan_config.feature_model_normalize_mean,'feature_model_normalize_std':esrgan_config.feature_model_normalize_std,'model_lr':esrgan_config.model_lr,'model_betas':esrgan_config.model_betas,'model_eps':esrgan_config.model_eps,'model_weight_decay':esrgan_config.model_weight_decay,'model_ema_decay':esrgan_config.model_ema_decay,'lr_scheduler_milestones':esrgan_config.lr_scheduler_milestones,'lr_scheduler_gamma':esrgan_config.lr_scheduler_gamma,'lpips_net':esrgan_config.lpips_net,'niqe_model_path':esrgan_config.niqe_model_path})\n",
    "\n",
    "\n",
    "    for epoch in range(start_epoch, esrgan_config.epochs):\n",
    "        pixel_loss, content_loss, adversarial_loss, d_gt_probabilities, d_sr_probabilities= train(d_model,\n",
    "              g_model,\n",
    "              ema_g_model,\n",
    "              train_prefetcher,\n",
    "              pixel_criterion,\n",
    "              content_criterion,\n",
    "              adversarial_criterion,\n",
    "              d_optimizer,\n",
    "              g_optimizer,\n",
    "              epoch,\n",
    "              scaler,\n",
    "              writer)\n",
    "\n",
    "        psnr_val, ssim_val, niqe_val, lpips_val = validate(g_model,\n",
    "                              valid_prefetcher,\n",
    "                              epoch,\n",
    "                              writer,\n",
    "                              psnr_model,\n",
    "                              ssim_model,\n",
    "                              niqe_model,\n",
    "                              lpips_model,\n",
    "                              \"Valid\")\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "        log_epoch(g_model, d_model, pixel_loss, content_loss, adversarial_loss, d_gt_probabilities, d_sr_probabilities, psnr_val, ssim_val, niqe_val, lpips_val, epoch)\n",
    "\n",
    "        # Update LR\n",
    "        d_scheduler.step()\n",
    "        g_scheduler.step()\n",
    "\n",
    "        # Save the best model with the highest LPIPS score in validation dataset\n",
    "        is_best = lpips_val < best_lpips_metrics\n",
    "        best_lpips_metrics = min(lpips_val, best_lpips_metrics)\n",
    "\n",
    "        if is_best:\n",
    "          print(\"Saving best model...\")\n",
    "          mlflow.pytorch.log_model(g_model, \"g_model\")\n",
    "          mlflow.pytorch.log_model(d_model, \"d_model\")\n",
    "          print(\"Finished Saving\")\n",
    "        else:\n",
    "          print(\"Was not the best\")\n",
    "\n",
    "    # End logging\n",
    "    mlflow.end_run()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "def log_epoch(g_model, d_model, g_pixel_loss, g_content_loss, g_adversarial_loss, d_gt_probabilities, d_sr_probabilities, psnr_val, ssim_val, niqe_val, lpips_val, epoch):\n",
    "    '''\n",
    "    g_pixel_loss, g_content_loss, g_adversarial_loss: train generator loss\n",
    "    d_gt_probabilities, d_sr_probabilities: descriminator probabilities\n",
    "    psnr, ssim, niqe, lpips: validation metrics\n",
    "    '''\n",
    "\n",
    "    print('\\nLogging epoch data...')\n",
    "\n",
    "    g_train_loss = g_pixel_loss + g_content_loss + g_adversarial_loss\n",
    "\n",
    "    mlflow.log_metrics({'g_train_loss':g_train_loss, 'g_pixel_loss':g_pixel_loss, 'g_content_loss':g_content_loss, 'g_adversarial_loss':g_adversarial_loss, 'd_gt_probabilities':d_gt_probabilities, 'd_sr_probabilities':d_sr_probabilities, 'psnr_val':psnr_val, 'ssim_val':ssim_val, 'niqe_val':niqe_val, 'lpips_val':lpips_val}, step=epoch)\n",
    "\n",
    "    print('Finished Logging\\n')\n",
    "\n",
    "\n",
    "def load_dataset() -> [CUDAPrefetcher, CUDAPrefetcher]:\n",
    "    # Load train, test and valid datasets\n",
    "    train_datasets = TrainValidImageDataset(esrgan_config.train_gt_images_dir,\n",
    "                                            esrgan_config.gt_image_size,\n",
    "                                            esrgan_config.upscale_factor,\n",
    "                                            \"Train\")\n",
    "    '''valid_datasets = TestImageDataset(esrgan_config.valid_gt_images_dir, esrgan_config.valid_lr_images_dir)\n",
    "    test_datasets = TestImageDataset(esrgan_config.test_gt_images_dir, esrgan_config.test_lr_images_dir)'''\n",
    "\n",
    "    valid_datasets = TrainValidImageDataset(esrgan_config.valid_gt_images_dir,\n",
    "                                        esrgan_config.gt_image_size,\n",
    "                                        esrgan_config.upscale_factor,\n",
    "                                        \"Valid\")\n",
    "\n",
    "    # Generator all dataloader\n",
    "    train_dataloader = DataLoader(train_datasets,\n",
    "                                  batch_size=esrgan_config.batch_size,\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=esrgan_config.num_workers,\n",
    "                                  pin_memory=True,\n",
    "                                  drop_last=True,\n",
    "                                  persistent_workers=True)\n",
    "    \n",
    "    valid_dataloader = DataLoader(valid_datasets,\n",
    "                                 batch_size=1,\n",
    "                                 shuffle=False,\n",
    "                                 num_workers=1,\n",
    "                                 pin_memory=True,\n",
    "                                 drop_last=False,\n",
    "                                 persistent_workers=True)\n",
    "\n",
    "    # Place all data on the preprocessing data loader\n",
    "    train_prefetcher = CUDAPrefetcher(train_dataloader, esrgan_config.device)\n",
    "    valid_prefetcher = CUDAPrefetcher(valid_dataloader, esrgan_config.device)\n",
    "\n",
    "    return train_prefetcher, valid_prefetcher\n",
    "\n",
    "\n",
    "def build_model() -> [nn.Module, nn.Module, nn.Module]:\n",
    "    d_model = model.__dict__[esrgan_config.d_arch_name]()\n",
    "    g_model = model.__dict__[esrgan_config.g_arch_name](in_channels=esrgan_config.in_channels,\n",
    "                                                        out_channels=esrgan_config.out_channels,\n",
    "                                                        channels=esrgan_config.channels,\n",
    "                                                        growth_channels=esrgan_config.growth_channels,\n",
    "                                                        num_blocks=esrgan_config.num_blocks)\n",
    "    d_model = d_model.to(device=esrgan_config.device)\n",
    "    g_model = g_model.to(device=esrgan_config.device)\n",
    "\n",
    "    # Create an Exponential Moving Average Model\n",
    "    ema_avg = lambda averaged_model_parameter, model_parameter, num_averaged: (1 - esrgan_config.model_ema_decay) * averaged_model_parameter + esrgan_config.model_ema_decay * model_parameter\n",
    "    ema_g_model = AveragedModel(g_model, avg_fn=ema_avg)\n",
    "\n",
    "    return d_model, g_model, ema_g_model\n",
    "\n",
    "\n",
    "def define_loss() -> [nn.L1Loss, model.content_loss, nn.BCEWithLogitsLoss]:\n",
    "    pixel_criterion = nn.L1Loss()\n",
    "    content_criterion = model.content_loss(esrgan_config.feature_model_extractor_node,\n",
    "                                           esrgan_config.feature_model_normalize_mean,\n",
    "                                           esrgan_config.feature_model_normalize_std)\n",
    "    adversarial_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Transfer to CUDA\n",
    "    pixel_criterion = pixel_criterion.to(device=esrgan_config.device)\n",
    "    content_criterion = content_criterion.to(device=esrgan_config.device)\n",
    "    adversarial_criterion = adversarial_criterion.to(device=esrgan_config.device)\n",
    "\n",
    "    return pixel_criterion, content_criterion, adversarial_criterion\n",
    "\n",
    "\n",
    "def define_optimizer(d_model, g_model) -> [optim.Adam, optim.Adam]:\n",
    "    d_optimizer = optim.Adam(d_model.parameters(),\n",
    "                             esrgan_config.model_lr,\n",
    "                             esrgan_config.model_betas,\n",
    "                             esrgan_config.model_eps,\n",
    "                             esrgan_config.model_weight_decay)\n",
    "    g_optimizer = optim.Adam(g_model.parameters(),\n",
    "                             esrgan_config.model_lr,\n",
    "                             esrgan_config.model_betas,\n",
    "                             esrgan_config.model_eps,\n",
    "                             esrgan_config.model_weight_decay)\n",
    "\n",
    "    return d_optimizer, g_optimizer\n",
    "\n",
    "\n",
    "def define_scheduler(\n",
    "        d_optimizer: optim.Adam,\n",
    "        g_optimizer: optim.Adam\n",
    ") -> [lr_scheduler.MultiStepLR, lr_scheduler.MultiStepLR]:\n",
    "    d_scheduler = lr_scheduler.MultiStepLR(d_optimizer,\n",
    "                                           esrgan_config.lr_scheduler_milestones,\n",
    "                                           esrgan_config.lr_scheduler_gamma)\n",
    "    g_scheduler = lr_scheduler.MultiStepLR(g_optimizer,\n",
    "                                           esrgan_config.lr_scheduler_milestones,\n",
    "                                           esrgan_config.lr_scheduler_gamma)\n",
    "    return d_scheduler, g_scheduler\n",
    "\n",
    "\n",
    "def train(\n",
    "        d_model: nn.Module,\n",
    "        g_model: nn.Module,\n",
    "        ema_g_model: nn.Module,\n",
    "        train_prefetcher: CUDAPrefetcher,\n",
    "        pixel_criterion: nn.L1Loss,\n",
    "        content_criterion: model.content_loss,\n",
    "        adversarial_criterion: nn.BCEWithLogitsLoss,\n",
    "        d_optimizer: optim.Adam,\n",
    "        g_optimizer: optim.Adam,\n",
    "        epoch: int,\n",
    "        scaler: amp.GradScaler,\n",
    "        writer: SummaryWriter\n",
    "):\n",
    "    '''\n",
    "    Returns average of key metrics (all in progress meter)\n",
    "    '''\n",
    "    print(\"Training\")\n",
    "    # Calculate how many batches of data are in each Epoch\n",
    "    batches = len(train_prefetcher)\n",
    "    # Print information of progress bar during training\n",
    "    batch_time = AverageMeter(\"Time\", \":6.3f\")\n",
    "    data_time = AverageMeter(\"Data\", \":6.3f\")\n",
    "    pixel_losses = AverageMeter(\"Pixel loss\", \":6.6f\")\n",
    "    content_losses = AverageMeter(\"Content loss\", \":6.6f\")\n",
    "    adversarial_losses = AverageMeter(\"Adversarial loss\", \":6.6f\")\n",
    "    d_gt_probabilities = AverageMeter(\"D(GT)\", \":6.3f\")\n",
    "    d_sr_probabilities = AverageMeter(\"D(SR)\", \":6.3f\")\n",
    "    progress = ProgressMeter(batches,\n",
    "                             [batch_time, data_time,\n",
    "                              pixel_losses, content_losses, adversarial_losses,\n",
    "                              d_gt_probabilities, d_sr_probabilities],\n",
    "                             prefix=f\"Epoch: [{epoch + 1}]\")\n",
    "\n",
    "    # Put the generative network model in training mode\n",
    "    d_model.train()\n",
    "    g_model.train()\n",
    "\n",
    "    # Initialize the number of data batches to print logs on the terminal\n",
    "    batch_index = 0\n",
    "\n",
    "    # Initialize the data loader and load the first batch of data\n",
    "    train_prefetcher.reset()\n",
    "    batch_data = train_prefetcher.next()\n",
    "\n",
    "    # Get the initialization training time\n",
    "    end = time.time()\n",
    "\n",
    "    #limit = 12\n",
    "\n",
    "    while batch_data is not None:\n",
    "        # Calculate the time it takes to load a batch of data\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # Transfer in-memory data to CUDA devices to speed up training\n",
    "        gt = batch_data[\"gt\"].to(device=esrgan_config.device, non_blocking=True)\n",
    "        lr = batch_data[\"lr\"].to(device=esrgan_config.device, non_blocking=True)\n",
    "\n",
    "        # Set the real sample label to 1, and the false sample label to 0\n",
    "        batch_size, _, _, _ = gt.shape\n",
    "        real_label = torch.full([batch_size, 1], 1.0, dtype=gt.dtype, device=esrgan_config.device)\n",
    "        fake_label = torch.full([batch_size, 1], 0.0, dtype=gt.dtype, device=esrgan_config.device)\n",
    "\n",
    "        # Start training the generator model\n",
    "        # During generator training, turn off discriminator backpropagation\n",
    "        for d_parameters in d_model.parameters():\n",
    "            d_parameters.requires_grad = False\n",
    "\n",
    "        # Initialize generator model gradients\n",
    "        g_model.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Calculate the perceptual loss of the generator, mainly including pixel loss, feature loss and adversarial loss\n",
    "        with amp.autocast():\n",
    "            # Use the generator model to generate fake samples\n",
    "            sr = g_model(lr)\n",
    "            # Output discriminator to discriminate object probability\n",
    "            gt_output = d_model(gt.detach().clone())\n",
    "            sr_output = d_model(sr)\n",
    "            pixel_loss = esrgan_config.pixel_weight * pixel_criterion(sr, gt)\n",
    "            content_loss = esrgan_config.content_weight * content_criterion(sr, gt)\n",
    "            # Computational adversarial network loss\n",
    "            d_loss_gt = adversarial_criterion(gt_output - torch.mean(sr_output), fake_label) * 0.5\n",
    "            d_loss_sr = adversarial_criterion(sr_output - torch.mean(gt_output), real_label) * 0.5\n",
    "            adversarial_loss = esrgan_config.adversarial_weight * (d_loss_gt + d_loss_sr)\n",
    "            # Calculate the generator total loss value\n",
    "            g_loss = pixel_loss + content_loss + adversarial_loss\n",
    "        # Call the gradient scaling function in the mixed precision API to\n",
    "        # back-propagate the gradient information of the fake samples\n",
    "        scaler.scale(g_loss).backward()\n",
    "        # Encourage the generator to generate higher quality fake samples, making it easier to fool the discriminator\n",
    "        scaler.step(g_optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Update EMA\n",
    "        ema_g_model.update_parameters(g_model)\n",
    "        # Finish training the generator model\n",
    "\n",
    "        # Start training the discriminator model\n",
    "        # During discriminator model training, enable discriminator model backpropagation\n",
    "        for d_parameters in d_model.parameters():\n",
    "            d_parameters.requires_grad = True\n",
    "\n",
    "        # Initialize the discriminator model gradients\n",
    "        d_model.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Calculate the classification score of the discriminator model for real samples\n",
    "        with amp.autocast():\n",
    "            gt_output = d_model(gt)\n",
    "            sr_output = d_model(sr.detach().clone())\n",
    "            d_loss_gt = adversarial_criterion(gt_output - torch.mean(sr_output), real_label) * 0.5\n",
    "        # Call the gradient scaling function in the mixed precision API to\n",
    "        # back-propagate the gradient information of the fake samples\n",
    "        scaler.scale(d_loss_gt).backward(retain_graph=True)\n",
    "\n",
    "        # Calculate the classification score of the discriminator model for fake samples\n",
    "        with amp.autocast():\n",
    "            sr_output = d_model(sr.detach().clone())\n",
    "            d_loss_sr = adversarial_criterion(sr_output - torch.mean(gt_output), fake_label) * 0.5\n",
    "        # Call the gradient scaling function in the mixed precision API to\n",
    "        # back-propagate the gradient information of the fake samples\n",
    "        scaler.scale(d_loss_sr).backward()\n",
    "\n",
    "        # Calculate the total discriminator loss value\n",
    "        d_loss = d_loss_gt + d_loss_sr\n",
    "\n",
    "        # Improve the discriminator model's ability to classify real and fake samples\n",
    "        scaler.step(d_optimizer)\n",
    "        scaler.update()\n",
    "        # Finish training the discriminator model\n",
    "\n",
    "        # Calculate the score of the discriminator on real samples and fake samples,\n",
    "        # the score of real samples is close to 1, and the score of fake samples is close to 0\n",
    "        d_gt_probability = torch.sigmoid_(torch.mean(gt_output.detach()))\n",
    "        d_sr_probability = torch.sigmoid_(torch.mean(sr_output.detach()))\n",
    "\n",
    "        # Statistical accuracy and loss value for terminal data output\n",
    "        pixel_losses.update(pixel_loss.item(), lr.size(0))\n",
    "        content_losses.update(content_loss.item(), lr.size(0))\n",
    "        adversarial_losses.update(adversarial_loss.item(), lr.size(0))\n",
    "        d_gt_probabilities.update(d_gt_probability.item(), lr.size(0))\n",
    "        d_sr_probabilities.update(d_sr_probability.item(), lr.size(0))\n",
    "\n",
    "        # Calculate the time it takes to fully train a batch of data\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # Write the data during training to the training log file\n",
    "        if batch_index % esrgan_config.train_print_frequency == 0:\n",
    "            iters = batch_index + epoch * batches + 1\n",
    "            writer.add_scalar(\"Train/D_Loss\", d_loss.item(), iters)\n",
    "            writer.add_scalar(\"Train/G_Loss\", g_loss.item(), iters)\n",
    "            writer.add_scalar(\"Train/Pixel_Loss\", pixel_loss.item(), iters)\n",
    "            writer.add_scalar(\"Train/Content_Loss\", content_loss.item(), iters)\n",
    "            writer.add_scalar(\"Train/Adversarial_Loss\", adversarial_loss.item(), iters)\n",
    "            writer.add_scalar(\"Train/D(GT)_Probability\", d_gt_probability.item(), iters)\n",
    "            writer.add_scalar(\"Train/D(SR)_Probability\", d_sr_probability.item(), iters)\n",
    "            progress.display(batch_index + 1)\n",
    "\n",
    "        # Preload the next batch of data\n",
    "        batch_data = train_prefetcher.next()\n",
    "\n",
    "        # After training a batch of data, add 1 to the number of data batches to ensure that the\n",
    "        # terminal print data normally\n",
    "        batch_index += 1\n",
    "\n",
    "        #if batch_index>limit:\n",
    "        #  print('Batch limit reached')\n",
    "        #  return pixel_losses.avg, content_losses.avg, adversarial_losses.avg, d_gt_probabilities.avg, d_sr_probabilities.avg\n",
    "\n",
    "    return pixel_losses.avg, content_losses.avg, adversarial_losses.avg, d_gt_probabilities.avg, d_sr_probabilities.avg\n",
    "\n",
    "\n",
    "def validate(\n",
    "        g_model: nn.Module,\n",
    "        data_prefetcher: CUDAPrefetcher,\n",
    "        epoch: int,\n",
    "        writer: SummaryWriter,\n",
    "        psnr_model: nn.Module,\n",
    "        ssim_model: nn.Module,\n",
    "        niqe_model: nn.Module,\n",
    "        lpips_model: nn.Module,\n",
    "        mode: str\n",
    ") -> [float, float, float]:\n",
    "    # Calculate how many batches of data are in each Epoch\n",
    "    batch_time = AverageMeter(\"Time\", \":6.3f\")\n",
    "    psnres = AverageMeter(\"PSNR\", \":4.2f\")\n",
    "    ssimes = AverageMeter(\"SSIM\", \":4.4f\")\n",
    "    niqees = AverageMeter(\"NIQE\", \":4.2f\")\n",
    "    lpipses = AverageMeter(\"LPIPS\", \":4.4f\")\n",
    "    progress = ProgressMeter(len(data_prefetcher), [batch_time, psnres, ssimes, niqees, lpipses], prefix=f\"{mode}: \")\n",
    "\n",
    "    print_freq = 1\n",
    "    if mode == \"Valid\":\n",
    "      print_freq = esrgan_config.valid_print_frequency\n",
    "    else:\n",
    "      print_freq = esrgan_config.test_print_frequency\n",
    "\n",
    "    # Put the adversarial network model in validation mode\n",
    "    g_model.eval()\n",
    "\n",
    "    # Initialize the number of data batches to print logs on the terminal\n",
    "    batch_index = 0\n",
    "\n",
    "    #limit = 20\n",
    "\n",
    "    # Initialize the data loader and load the first batch of data\n",
    "    data_prefetcher.reset()\n",
    "    batch_data = data_prefetcher.next()\n",
    "\n",
    "    # Get the initialization test time\n",
    "    end = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        while batch_data is not None:\n",
    "            # Transfer the in-memory data to the CUDA device to speed up the test\n",
    "            gt = batch_data[\"gt\"].to(device=esrgan_config.device, non_blocking=True)\n",
    "            lr = batch_data[\"lr\"].to(device=esrgan_config.device, non_blocking=True)\n",
    "\n",
    "            # Use the generator model to generate a fake sample\n",
    "            with amp.autocast():\n",
    "                sr = g_model(lr)\n",
    "\n",
    "            # Statistical loss value for terminal data output\n",
    "            psnr = psnr_model(sr, gt)\n",
    "            ssim = ssim_model(sr, gt)\n",
    "            niqe = niqe_model(sr)\n",
    "            sr_tensor = 2*sr - 1 # Normalize from [0,1] to [-1,1]\n",
    "            gt_tensor = 2*gt - 1\n",
    "            lpips = lpips_model(sr, gt)\n",
    "\n",
    "            psnres.update(psnr.item(), lr.size(0))\n",
    "            ssimes.update(ssim.item(), lr.size(0))\n",
    "            niqees.update(niqe.item(), lr.size(0))\n",
    "            lpipses.update(lpips.item(), lr.size(0))\n",
    "\n",
    "            # Calculate the time it takes to fully test a batch of data\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            # Record training log information\n",
    "            if batch_index % print_freq == 0:\n",
    "                progress.display(batch_index + 1)\n",
    "\n",
    "            # Preload the next batch of data\n",
    "            batch_data = data_prefetcher.next()\n",
    "\n",
    "            # After training a batch of data, add 1 to the number of data batches to ensure that the\n",
    "            # terminal print data normally\n",
    "            batch_index += 1\n",
    "\n",
    "            #if batch_index > limit:\n",
    "            #  print(\"Limit reached\")\n",
    "            #  break\n",
    "\n",
    "    # print metrics\n",
    "    progress.display_summary()\n",
    "\n",
    "    if mode == \"Valid\" or mode == \"Test\":\n",
    "        writer.add_scalar(f\"{mode}/PSNR\", psnres.avg, epoch + 1)\n",
    "        writer.add_scalar(f\"{mode}/SSIM\", ssimes.avg, epoch + 1)\n",
    "        writer.add_scalar(f\"{mode}/NIQE\", niqees.avg, epoch + 1)\n",
    "        writer.add_scalar(f\"{mode}/LPIPS\", lpipses.avg, epoch + 1)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported mode, please use `Valid` or `Test`.\")\n",
    "\n",
    "    return psnres.avg, ssimes.avg, niqees.avg, lpipses.avg\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kJb7mH1J0QEl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-03-21 16:14:55 +0000] [3880] [INFO] Starting gunicorn 20.1.0\n",
      "[2023-03-21 16:14:55 +0000] [3880] [INFO] Listening at: http://127.0.0.1:5000 (3880)\n",
      "[2023-03-21 16:14:55 +0000] [3880] [INFO] Using worker: sync\n",
      "[2023-03-21 16:14:55 +0000] [3881] [INFO] Booting worker with pid: 3881\n",
      "[2023-03-21 16:14:55 +0000] [3882] [INFO] Booting worker with pid: 3882\n",
      "[2023-03-21 16:14:55 +0000] [3883] [INFO] Booting worker with pid: 3883\n",
      "[2023-03-21 16:14:55 +0000] [3884] [INFO] Booting worker with pid: 3884\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed run '.ipynb_checkpoints'. Detailed error Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 857, in _list_run_infos\n",
      "    run_info = self._get_run_info_from_dir(r_dir)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 668, in _get_run_info_from_dir\n",
      "    meta = FileStore._read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1083, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1076, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 214, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file './mlruns/458631362597146827/.ipynb_checkpoints/meta.yaml' does not exist.\n",
      "^C\n",
      "[2023-03-21 16:28:08 +0000] [3880] [INFO] Handling signal: int\n",
      "[2023-03-21 16:28:08 +0000] [3882] [INFO] Worker exiting (pid: 3882)\n",
      "[2023-03-21 16:28:08 +0000] [3881] [INFO] Worker exiting (pid: 3881)\n",
      "[2023-03-21 16:28:08 +0000] [3883] [INFO] Worker exiting (pid: 3883)\n",
      "[2023-03-21 16:28:08 +0000] [3884] [INFO] Worker exiting (pid: 3884)\n"
     ]
    }
   ],
   "source": [
    " !mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdzON023C04C"
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 99796,
     "status": "ok",
     "timestamp": 1678816558932,
     "user": {
      "displayName": "Miguel Neves",
      "userId": "01323576189800675186"
     },
     "user_tz": 0
    },
    "id": "F2YOIBU3ZKLL",
    "outputId": "ab15dfc7-b000-4180-e84c-7fe7552cf680"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/miguelneves/anaconda3/envs/superres/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "PSNR: 29.40 [dB]\n",
      "SSIM: 0.8759 [u]\n",
      "NIQE: 9.19 [100u]\n",
      "LPIPS: 0.07 [100u]\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2022 Dakewe Biotech Corporation. All Rights Reserved.\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#   you may not use this file except in compliance with the License.\n",
    "#   You may obtain a copy of the License at\n",
    "#\n",
    "#       http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "from natsort import natsorted\n",
    "\n",
    "import esrgan_config\n",
    "import mlflow\n",
    "import imgproc\n",
    "import model\n",
    "from image_quality_assessment import PSNR, SSIM, NIQE\n",
    "from lpips import LPIPS\n",
    "from utils import make_directory\n",
    "from dataset import CUDAPrefetcher, TrainValidImageDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "model_names = sorted(\n",
    "    name for name in model.__dict__ if\n",
    "    name.islower() and not name.startswith(\"__\") and callable(model.__dict__[name]))\n",
    "\n",
    "save_images = True\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "\n",
    "    # Set MLflow experiment & run\n",
    "    mlflow.set_experiment(esrgan_config.experience_name)\n",
    "    try:\n",
    "      mlflow.start_run(run_id=esrgan_config.run_id, tags=esrgan_config.tags, description=esrgan_config.description)\n",
    "    except: # If last session was not ended\n",
    "      mlflow.end_run()\n",
    "      mlflow.start_run(run_id=esrgan_config.run_id, tags=esrgan_config.tags, description=esrgan_config.description)\n",
    "\n",
    "\n",
    "    # Load Test Dataset\n",
    "    test_datasets = TrainValidImageDataset(esrgan_config.gt_dir,\n",
    "                                        0,\n",
    "                                        esrgan_config.upscale_factor,\n",
    "                                        \"Valid\")\n",
    "    \n",
    "    test_dataloader = DataLoader(test_datasets,\n",
    "                                 batch_size=1,\n",
    "                                 shuffle=False,\n",
    "                                 num_workers=1,\n",
    "                                 pin_memory=True,\n",
    "                                 drop_last=False,\n",
    "                                 persistent_workers=True)\n",
    "    \n",
    "    test_prefetcher = CUDAPrefetcher(test_dataloader, esrgan_config.device)\n",
    "    # Initialize the data loader and load the first batch of data\n",
    "    test_prefetcher.reset()\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize the super-resolution bsrgan_model\n",
    "    esrgan_model = model.__dict__[esrgan_config.g_arch_name](in_channels=esrgan_config.in_channels,\n",
    "                                                             out_channels=esrgan_config.out_channels,\n",
    "                                                             channels=esrgan_config.channels,\n",
    "                                                             growth_channels=esrgan_config.growth_channels,\n",
    "                                                             num_blocks=esrgan_config.num_blocks)\n",
    "    '''\n",
    "    esrgan_model = esrgan_model.to(device=esrgan_config.device)\n",
    "    print(f\"Build `{esrgan_config.g_arch_name}` model successfully.\")\n",
    "\n",
    "    # Load the super-resolution bsrgan_model weights\n",
    "    checkpoint = torch.load(esrgan_config.g_model_weights_path, map_location=lambda storage, loc: storage)\n",
    "    esrgan_model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    print(f\"Load `{esrgan_config.g_arch_name}` model weights \"\n",
    "          f\"`{os.path.abspath(esrgan_config.g_model_weights_path)}` successfully.\")\n",
    "    '''\n",
    "\n",
    "    \n",
    "    # Load Generator Model\n",
    "    g_model = mlflow.pytorch.load_model(esrgan_config.g_model_weights_path)\n",
    "    esrgan_model = g_model.to(device=esrgan_config.device)\n",
    "\n",
    "    # Create a folder of super-resolution experiment results\n",
    "    #make_directory(esrgan_config.sr_dir)\n",
    "\n",
    "    # Start the verification mode of the bsrgan_model.\n",
    "    esrgan_model.eval()\n",
    "\n",
    "    # Initialize the sharpness evaluation function\n",
    "    psnr = PSNR(esrgan_config.upscale_factor, esrgan_config.only_test_y_channel)\n",
    "    ssim = SSIM(esrgan_config.upscale_factor, esrgan_config.only_test_y_channel)\n",
    "    niqe = NIQE(esrgan_config.upscale_factor, esrgan_config.niqe_model_path)\n",
    "    lpips = LPIPS(net='alex')\n",
    "\n",
    "    # Set the sharpness evaluation function calculation device to the specified model\n",
    "    psnr = psnr.to(device=esrgan_config.device, non_blocking=True)\n",
    "    ssim = ssim.to(device=esrgan_config.device, non_blocking=True)\n",
    "    niqe = niqe.to(device=esrgan_config.device, non_blocking=True)\n",
    "    lpips = lpips.to(device=esrgan_config.device, non_blocking=True)\n",
    "\n",
    "    # Initialize IQA metrics\n",
    "    psnr_metrics = 0.0\n",
    "    ssim_metrics = 0.0\n",
    "    niqe_metrics = 0.0\n",
    "    lpips_metrics = 0.0\n",
    "\n",
    "    # Get a list of test image file names.\n",
    "    file_names = os.listdir(esrgan_config.gt_dir)\n",
    "    # Get the number of test image files.\n",
    "    total_files = int(len(file_names))\n",
    "\n",
    "    pathLR = \"testImagesLR/\"\n",
    "    pathTest = \"testImages/\"\n",
    "\n",
    "    for index in range(total_files):\n",
    "        '''\n",
    "        lr_image_path = os.path.join(esrgan_config.lr_dir, file_names[index])\n",
    "        sr_image_path = os.path.join(esrgan_config.sr_dir, file_names[index])\n",
    "        gt_image_path = os.path.join(esrgan_config.gt_dir, file_names[index])\n",
    "\n",
    "        print(f\"Processing `{os.path.abspath(lr_image_path)}`...\")\n",
    "        lr_tensor = imgproc.preprocess_one_image(lr_image_path, esrgan_config.device)\n",
    "        gt_tensor = imgproc.preprocess_one_image(gt_image_path, esrgan_config.device)\n",
    "        '''\n",
    "\n",
    "        batch_data = test_prefetcher.next()\n",
    "        gt_tensor = batch_data[\"gt\"].to(device=esrgan_config.device, non_blocking=True)\n",
    "        lr_tensor = batch_data[\"lr\"].to(device=esrgan_config.device, non_blocking=True)\n",
    "\n",
    "        lr_image = imgproc.tensor_to_image(lr_tensor, False, False)\n",
    "        lr_image = cv2.cvtColor(lr_image, cv2.COLOR_RGB2BGR)\n",
    "        mlflow.log_image(lr_image, pathLR+file_names[index])\n",
    "\n",
    "        # Only reconstruct the Y channel image data.\n",
    "        with torch.no_grad():\n",
    "            sr_tensor = esrgan_model(lr_tensor)\n",
    "\n",
    "        # Save image\n",
    "        if save_images:\n",
    "          sr_image = imgproc.tensor_to_image(sr_tensor, False, False)\n",
    "          sr_image = cv2.cvtColor(sr_image, cv2.COLOR_RGB2BGR)\n",
    "          mlflow.log_image(sr_image, pathTest+file_names[index])\n",
    "          #cv2.imwrite(sr_image_path, sr_image)\n",
    "\n",
    "        # Cal IQA metrics\n",
    "        psnr_metrics += psnr(sr_tensor, gt_tensor).item()\n",
    "        ssim_metrics += ssim(sr_tensor, gt_tensor).item()\n",
    "        niqe_metrics += niqe(sr_tensor).item()\n",
    "        \n",
    "        sr_tensor = 2*sr_tensor - 1 # Normalize from [0,1] to [-1,1]\n",
    "        gt_tensor = 2*gt_tensor - 1\n",
    "        lpips_metrics += lpips(sr_tensor, gt_tensor).item()\n",
    "\n",
    "    # Calculate the average value of the sharpness evaluation index,\n",
    "    # and all index range values are cut according to the following values\n",
    "    # PSNR range value is 0~100\n",
    "    # SSIM range value is 0~1\n",
    "    # NIQE range value is 0~100 although it can go to infinite. Typically a score higher than 10 is bad and lower than 2 is excelent\n",
    "    avg_psnr = 100 if psnr_metrics / total_files > 100 else psnr_metrics / total_files\n",
    "    avg_ssim = 1 if ssim_metrics / total_files > 1 else ssim_metrics / total_files\n",
    "    avg_niqe = 100 if niqe_metrics / total_files > 100 else niqe_metrics / total_files\n",
    "    avg_lpips = 100 if lpips_metrics / total_files > 100 else lpips_metrics / total_files\n",
    " \n",
    "    print(f\"PSNR: {avg_psnr:4.2f} [dB]\\n\"\n",
    "          f\"SSIM: {avg_ssim:4.4f} [u]\\n\"\n",
    "          f\"NIQE: {avg_niqe:4.2f} [100u]\\n\"\n",
    "          f\"LPIPS: {avg_lpips:4.2f} [100u]\")\n",
    "    \n",
    "    mlflow.end_run()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uzyqAkSLC3Lh"
   },
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPP+S4dQ8BH6FlB5QXAKUd8",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
